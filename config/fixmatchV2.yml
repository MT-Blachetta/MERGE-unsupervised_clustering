setup: fixmatch
#prefix: SCAN_test_mlpHead

consistency_weights: False
train_method: fixmatchV2 # or fixmatchV1
indexfile_path: /home/blachm86/train_unlabeled_5p.ind
train_split: train+unlabeled
epochs: 100
warmup_epochs: 50

fixmatch_model:
    backbone: ResNet34
    model_type: cc_network
    feature_dim: 128
    pretrain_type: cc_resnet
    pretrain_path: /home/blachm86/backbone_models/cc_stl10.tar

### Technical Parameters (unimportant) FIXED
num_workers: 8

### Universal Parameters

batch_size: 256

update_cluster_head_only: False


## !!!fixed!!! dataset related Parameters

num_classes: 10
train_db_name: stl-10
val_db_name: stl-10


## nearest neighbors scan loss related
# for model training
neighbor_prefix: scatnet_test
neighbor_prefix_val: scatnet_test
to_augmented_dataset: False # mode variable
to_neighbors_dataset: False




### AUGMENTATION related

# <dependent>
augmentation_type: scan
augmentation_strategy: ours

augmentation_kwargs:
   random_resized_crop:
      size: 96
      scale: [0.2, 1.0]
   local_crops_number: 0 
   crop_size: 96
   num_strong_augs: 4
   cutout_kwargs:
     n_holes: 1
     length: 25
     random: True
   color_jitter_random_apply:
      p: 0.8
   color_jitter:
      brightness: 0.4
      contrast: 0.4
      saturation: 0.4
      hue: 0.1
   random_grayscale: 
      p: 0.2
   normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
# <dependent>

transformation_kwargs: 
   crop_size: 96
   normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]


### MODEL related

## backbone

# <dependent>
backbone: scatnet
pretrain_type: scan
#pretrain_path: /home/blachm86/backbone_models/SCAN_best.pth
feature_dim: 128

hidden_dim: 128
scatnet_args: 
    J: 2
    L: 16
    input_size: [96, 96, 3] 
    res_blocks: 30
    out_dim: 128

#hidden_dim: 4096 # parameter for [backbone]:twist
# <dependent>
num_heads: 10
#model_type: clusterHeads
# <dependent>

model_args: # softmax is performed over loss function
    head_type: mlp
    aug_type: default
    batch_norm: True
    last_batchnorm: False
    last_activation: softmax
    drop_out: -1






## head
labeled_samples_ratio: 0.05
confidence_threshold: 0.95
temperature: 0.5
lambda_u: 1
# <dependent>



### Training Algorithm with loss function





loss_type: scan_loss
entropy_weight: 5.0 # scan_loss parameter

### Training Process Parameter


## optimizer




# VERSION

optimizer: sgd
optimizer_kwargs:
   nesterov: True
   weight_decay: 0.0003
   momentum: 0.9
   lr: 0.03



scheduler: constant
#scheduler_kwargs:
#   lr_decay_rate: 0.1
   
## Scheduler
#scheduler: constant


#optimizer: sgd
#optimizer_kwargs:
#   nesterov: False
#   weight_decay: 0.0001 
#   momentum: 0.9
#   lr: 0.4