setup: fixmatch
#prefix: SCAN_test_mlpHead

### Technical Parameters (unimportant) FIXED
num_workers: 8

### Universal Parameters
epochs: 2
batch_size: 512

update_cluster_head_only: False


## !!!fixed!!! dataset related Parameters

num_classes: 10
train_db_name: stl-10
val_db_name: stl-10
train_split: unlabeled

## nearest neighbors scan loss related
# for model training
neighbor_prefix: scatnet_test
neighbor_prefix_val: scatnet_test
to_augmented_dataset: False # mode variable
to_neighbors_dataset: False




### AUGMENTATION related

# <dependent>
augmentation_type: scan
augmentation_strategy: ours

augmentation_kwargs:
   random_resized_crop:
      size: 96
      scale: [0.2, 1.0]
   local_crops_number: 0 
   crop_size: 96
   num_strong_augs: 4
   cutout_kwargs:
     n_holes: 1
     length: 25
     random: True
   color_jitter_random_apply:
      p: 0.8
   color_jitter:
      brightness: 0.4
      contrast: 0.4
      saturation: 0.4
      hue: 0.1
   random_grayscale: 
      p: 0.2
   normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
# <dependent>

transformation_kwargs: 
   crop_size: 96
   normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]


### MODEL related

## backbone

# <dependent>
backbone: scatnet
pretrain_path: /home/blachm86/backbone_models/SCAN_best.pth
feature_dim: 128
hidden_dim: 128
scatnet_args: 
    J: 2
    L: 16
    input_size: [96, 96, 3] 
    res_blocks: 30
    out_dim: 128

#hidden_dim: 4096 # parameter for [backbone]:twist
# <dependent>
num_heads: 10
model_type: clusterHeads
# <dependent>

model_args: # softmax is performed over loss function
    head_type: mlp
    aug_type: default
    batch_norm: False
    last_batchnorm: False
    last_activation: None
    drop_out: -1

fixmatch_model:
    backbone: ResNet34
    model_type: cc_network
    feature_dim: 128
    pretrain_path: /home/blachm86/backbone_models/cc_stl10_ra.pth


## head
labeled_samples_ratio: 0.05
confidence_threshold: 0.99
temperature: 0.5
lambda_u: 0.5
# <dependent>



### Training Algorithm with loss function

train_method: scan
loss_type: scan_loss
entropy_weight: 5.0 # scan_loss parameter

### Training Process Parameter


## optimizer

# VERSION
optimizer: adam
optimizer_kwargs:
   lr: 0.0001
   weight_decay: 0.0001



## Scheduler
scheduler: constant
scheduler_kwargs:
   lr_decay_rate: 0.1